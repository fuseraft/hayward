package csv
  fn parse_csv(csv_file_path: string, delimiter: string = ",", has_header_row: boolean = false): list
    var (p = CSVParser.new(csv_file_path, delimiter))
    var (csv_list: list = p.parse_csv())
    return CSVParser.hashify(csv_list, has_header_row);
;

export "csv"

struct CSVParser
  fn new(input_path: string, delimiter: string = ",")
    var (lines: list = fio::readlines(input_path))
    @line_no = -1
    @lines = lines
    @max_lines = lines.size()
    @delimiter = delimiter;

  static fn hashify(csv_list: list = [], header_row: boolean = false): list
    return {} when csv_list.empty()

    var (cols: list = [])
    if header_row
      cols.concat(csv_list.first())
    else
      for i in [0..csv_list.size()] do
        cols.push(i);
    ;

    var (res: list = [])

    for row, row_index in csv_list do
      next when header_row && row_index == 0
      
      var (res_row: hashmap = {})
      
      for item, col_index in row do
        key = cols[col_index]
        res_row.set(key, item);

      res.push(res_row);

    return res;
    
  # Parse the entire CSV stream into a 2D list of strings.
  fn parse_csv(): list
    var (data: list = [])
    var (raw_line: string = "")

    # Keep reading until EOF
    while true do
      var (res: hashmap = fetch_next_record())
      var (success: boolean = res.success)
      var (record: string = res.record)
      break when !success
      
      var (row: list = parse_line(record))
      data.push(row.clone());

    return data;

  private fn get_line(): string
    var (lines: list = @lines)

    if can_read()
      var (line: string = @lines.get(@line_no + 1))
      @line_no += 1
      return line;
  ;

  private fn can_read(): boolean
    return !@lines.empty() && @line_no + 1 < @max_lines;

  private fn csv_error(msg: string = "An error occurred")
    msg += "\nLine: ${@line_no}"
    return msg;

  # Reads enough lines to form a complete CSV record if multiline fields are present.
  # Returns false if no more complete records can be read.
  private fn fetch_next_record(): hashmap
    # State to track if we're currently inside quotes (to handle multiline)
    var (in_quotes: boolean = false)
    var (buffer: string)
    var (out_record: string = "")

    while true do
      var (has_next: boolean = can_read())

      # If we can't read a new line and we're not currently building a record,
      # it means we've reached EOF.
      return { "success": false, "record": out_record }
        when !has_next

      # If we have partially read an in_quotes line and never closed it, it's malformed.
      throw csv_error("Unterminated quoted field at EOF")
        when !has_next && in_quotes

      buffer = get_line()

      if out_record.empty()
        # Start fresh from this line
        out_record = buffer.clone()
      else
        # We're continuing a multiline field
        out_record += "\n"
        out_record += buffer.clone();

      # Check if the current combined line is balanced in terms of quotes
      # We'll do a quick scan counting quotes that are not doubled.

      var (res: hashmap = line_is_complete(out_record))
      var (line_complete: boolean = res.complete)
      in_quotes = res.in_quotes

      # Once we have a line where in_quotes ends as false, we have a complete record
      break when line_complete && !in_quotes;

    return { "success": true, "record": out_record };

    # Parses a single "complete" CSV line into fields.
  fn parse_line(line: string): list
    var (fields: list = [])
    var (field: string = "")
    var (i: integer = 0)
    var (length: integer = line.chars().size())
    var (quotes: integer = 0)

    while i < length do
      var (c = line[i])

      if quotes > 0
        # If inside quotes
        if c == "\""
          # Check if this is an escaped quote
          if (i + 1 < length && line[i+1] == "\"")
            # It's an escaped quote, add a literal quote to field
            field += "\""
            i += 1 # Skip next quote
          else
            # It's a closing quote
            quotes -= 1;
        else
          # Regular character inside quotes
          field += c;
      else
        # Outside quotes
        if c == @delimiter
          # End of field
          fields.push(field.clone())
          field = ""
        elsif c == "\""
          # Starting a quoted field
          quotes += 1
        else
          # Regular character outside quotes
          field += c;
      ;

      i += 1;

    # Add the last field
    fields.push(field.clone())

    # If still in quotes at the end, it's malformed.
    # This should be caught earlier by `fetch_next_record()` logic.
    # But let's double-check for safety.
    throw csv_error("Unterminated quoted field.")
      when quotes > 0

    return fields;

  fn line_is_complete(line: string): hashmap
    var (in_quotes: boolean = false)
    var (i: integer = 0)
    var (length: integer = line.size())

    while i < length do
      var (c = line[i])
      if c == "\""
        if in_quotes
          # Check if escaped quote
          if i + 1 < length && line[i + 1] == "\""
            i += 1
          else
            in_quotes = false;
        else
          in_quotes = true;
      ;
      i += 1;

    return { "complete": !in_quotes, "in_quotes": in_quotes };
;